{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation Libraaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Date Manipulation Library\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Scrapping Libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from html_table_parser.parser import HTMLTableParser\n",
    "\n",
    "\n",
    "# Statistical Analysis Libraries\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The link for the Tely 10 race data. We have created a list with Years and the link\n",
    "\n",
    "year_link = [\n",
    "            [    1978,'https://www.nlaa.ca/results/rr/1978/19780625_Tely-10.php',                                ],\n",
    "            [    1981,'https://www.nlaa.ca/results/rr/1981/19810712_54th_Tely_10.php',                           ],\n",
    "            [    1982,'https://www.nlaa.ca/results/rr/1982/1982_0711_55th_Tely_10_Atlantic_Championships.php',   ],\n",
    "            [    1984,'https://www.nlaa.ca/results/rr/1984/19840715_Tely_10.php',                                ],\n",
    "            [    1985,'https://www.nlaa.ca/results/rr/1985/19850714_Tely_10.php',                                ],\n",
    "            [    1986,'https://www.nlaa.ca/results/rr/1986/1986_07_06_59th_Tely_10.php',                         ],\n",
    "            [    1987,'https://www.nlaa.ca/results/rr/1987/19870705_60th_Tely_10.php',                           ],\n",
    "            [    1988, 'https://www.nlaa.ca/results/rr/1988/19880717_61st_Tely10.php',                           ],\n",
    "            [    1990,'https://www.nlaa.ca/results/rr/1990/19900715_63rd_Tely_10.php',                           ],\n",
    "            [    1991,'https://www.nlaa.ca/results/rr/1991/19910714_64th_Tely_10.php',                           ],\n",
    "            [    1992,'https://www.nlaa.ca/results/rr/1992/19920712-Tely10.php',                                 ],\n",
    "            [    1996,'https://www.nlaa.ca/results/rr/1996/19960714-tely10.php',                                 ],\n",
    "            [    1997,'https://www.nlaa.ca/results/rr/1997/19970713-tely-10.php',                                 ],\n",
    "            [    1998,'https://www.nlaa.ca/results/rr/1998/19980712-tely-10.php',                                ],\n",
    "            [    1999,'https://www.nlaa.ca/results/rr/1999/19990711-tely-10.php',                                ],\n",
    "            [    2000,'https://www.nlaa.ca/results/rr/2000/20000716-tely-10.php',                                ],\n",
    "            [    2001,'https://www.nlaa.ca/results/rr/2001/20010722-tely-10.php',                                ],\n",
    "            [    2002,'https://www.nlaa.ca/results/rr/2002/20020728-tely-10.php',                                ],\n",
    "            [    2003,'https://www.nlaa.ca/results/rr/2003/20030727-tely-10.php',                                ],\n",
    "            [    2004,'https://www.nlaa.ca/results/rr/2004/20040725-tely-10.php',                                ],\n",
    "            [    2005,'https://www.nlaa.ca/results/rr/2005/20050724_tely_10.php',                                ],\n",
    "            [    2006,'https://www.nlaa.ca/results/rr/2006/20060723_tely_10.php',                                ],\n",
    "            [    2007,'https://www.nlaa.ca/results/rr/2007/0722tely10.php',                                      ],\n",
    "            [    2008,'https://www.nlaa.ca/results/rr/2008/0727tely10.php',                                      ],\n",
    "            [    2009,'https://www.nlaa.ca/results/rr/2009/0726tely10.php',                                      ],\n",
    "            [    2010,'https://www.nlaa.ca/results/rr/2010/2010tely10results.php',                               ],\n",
    "            [    2011,'https://www.nlaa.ca/results/rr/2011/2011tely10results.php',                               ],\n",
    "            [    2012,'https://www.nlaa.ca/results/rr/2012/20120722tely10results.php',                           ],\n",
    "            [    2013,'https://www.nlaa.ca/results/rr/2013/20130728tely10results.php',                           ],\n",
    "            [    2014,'https://www.nlaa.ca/results/rr/2014/20140727tely10results.php',                           ],\n",
    "            [    2015,'https://www.nlaa.ca/results/rr/2015/20150726tely10results.php',                           ],\n",
    "            [    2016,'https://www.nlaa.ca/results/rr/2016/20160724tely10results.php',                           ],\n",
    "            [    2017,'https://www.nlaa.ca/results/rr/2017/20170723tely10results.php',                           ],\n",
    "            [    2018,'https://www.nlaa.ca/results/rr/2018/20180722tely10results.php',                           ],\n",
    "            [    2019,'https://www.nlaa.ca/results/rr/2019/20190728-tely10-results.php',                         ],\n",
    "            [    2021,'https://www.nlaa.ca/results/rr/2021/20211031-tely10-results.php',                         ],\n",
    "            [    2022,'https://www.nlaa.ca/results/rr/2022/20221008-tely10-results.php',                         ],\n",
    "            [    2023,'https://www.nlaa.ca/results/rr/2023/20230625-tely10-results.php'                          ]\n",
    "            \n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Going over the URL for Race Data. This part is mainly for Scrapping the data from the website.\n",
    "\n",
    "\n",
    "for year, url in year_link:\n",
    "\n",
    "    \n",
    "\n",
    "    # Send GET request to the website\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML code using BeautifulSoup\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract relevant data from the scraped HTML code\n",
    "\n",
    "    p = HTMLTableParser()\n",
    "\n",
    "    table_data = soup.find('pre').text\n",
    "    row = []\n",
    "    ls = []\n",
    "\n",
    "    \n",
    "\n",
    "    # Iterating over each row of the data scrapped.\n",
    "\n",
    "\n",
    "    for idx, line in enumerate(table_data.split('\\n')[1:]):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        # The format of the race changes over years. We are extracting the data from the website. The data is stored in a list of string and we index the values. \n",
    "        # The index for the data in the list has changes over the years.\n",
    "\n",
    "        if year == 1997:\n",
    "\n",
    "            # 2003, 2004\n",
    "\n",
    "            position = line[0:3]\n",
    "            bib = line[6:9]\n",
    "            Name = line[11:35]\n",
    "            time = line[39:48]\n",
    "            sex_category = line[51:52]\n",
    "            sex_rank = line[63:69]\n",
    "            rank_cat = line[55:60]\n",
    "            chip_time = line[63:65]\n",
    "            pace = line[63:65]\n",
    "            location = line[63:65]\n",
    "\n",
    "        elif year <= 2004:\n",
    "\n",
    "            # 2003, 2004\n",
    "\n",
    "            position = line[0:4]\n",
    "            bib = line[6:10]\n",
    "            Name = line[11:39]\n",
    "            time = line[40:48]\n",
    "            sex_category = line[49:57]\n",
    "            sex_rank = line[58:64]\n",
    "            rank_cat = line[65:69]\n",
    "            chip_time = line[70:78]\n",
    "            pace = line[79:85]\n",
    "            location = line[86:]\n",
    "\n",
    "\n",
    "        elif year == 2005:\n",
    "\n",
    "            # 2005\n",
    "\n",
    "\n",
    "            position = line[0:4]\n",
    "            bib = line[7:10]\n",
    "            Name = line[11:33]\n",
    "            time = line[34:42]\n",
    "            sex_category = line[43:51]\n",
    "            sex_rank = line[52:57]\n",
    "            rank_cat = line[61:64]\n",
    "            chip_time = line[72:79]\n",
    "            pace = line[65:71]\n",
    "            location = line[80:]\n",
    "\n",
    "\n",
    "        elif   2006 <= year <= 2014:        \n",
    "\n",
    "            # 2006\n",
    "\n",
    "\n",
    "            position = line[0:4]\n",
    "            bib = line[7:10]\n",
    "            Name = line[11:33]\n",
    "            time = line[34:42]\n",
    "            sex_category = line[43:51]\n",
    "            sex_rank = line[52:57]\n",
    "            rank_cat = line[61:64]\n",
    "            chip_time = line[72:80]\n",
    "            pace = line[67:72]\n",
    "            location = line[81:]\n",
    "        \n",
    "\n",
    "        elif   2014 <= year <= 2022:       \n",
    "\n",
    "            # 2014 onwards\n",
    "\n",
    "            position = line[0:5]\n",
    "            bib = line[6:10]\n",
    "            Name = line[11:42]\n",
    "            time = line[43:51]\n",
    "            sex_category = line[52:59]\n",
    "            sex_rank = line[60:69]\n",
    "            rank_cat = line[70:73]\n",
    "            chip_time = line[75:81]\n",
    "            pace = line[82:90]\n",
    "            location = line[91:]\n",
    "\n",
    "\n",
    "        elif   year == 2023:  \n",
    "            \n",
    "            # 2023\n",
    "\n",
    "            position = line[0:4]\n",
    "            bib = line[7:10]\n",
    "            Name = line[11:42]\n",
    "            time = line[43:51]\n",
    "            sex_category = line[52:59]\n",
    "            sex_rank = line[60:66]\n",
    "            rank_cat = line[70:75]\n",
    "            chip_time = line[77:86]\n",
    "            pace = line[67:77]\n",
    "            location = line[86:]\n",
    "\n",
    "\n",
    "        elif   year == 2024:\n",
    "\n",
    "            # 2024\n",
    "\n",
    "            position = line[0:5]\n",
    "            bib = line[6:10]\n",
    "            Name = line[11:42]\n",
    "            time = line[43:51]\n",
    "            sex_category = line[52:62]\n",
    "            sex_rank = line[63:69]\n",
    "            rank_cat = line[70:73]\n",
    "            chip_time = line[75:81]\n",
    "            pace = line[82:90]\n",
    "            location = line[91:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        row.append( [position,bib,Name,time,sex_category,sex_rank,rank_cat,chip_time,pace,location] )\n",
    "        # row = [i for i in row if i ]\n",
    "\n",
    "\n",
    "    # Creating a table to save the data.\n",
    "    \n",
    "    df = pd.DataFrame([])\n",
    "    df = df.append(row)\n",
    "    df['year'] = year\n",
    "\n",
    "    # Saving the Data\n",
    "\n",
    "    df.to_csv(fr'C:\\Users\\Monk\\Codebase\\Tely 10\\Tely 10 data {year}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to grooup years into a groups of 5 years. From 1978-1989, we are grouping the years into a single group since we don't have a lot of data berween those years.\n",
    "\n",
    "def year_group(x):\n",
    "\n",
    "\n",
    "    if  1978 <= x.Year <= 1989:\n",
    "\n",
    "        return '1978-1989' \n",
    "\n",
    "    elif  1990 <= x.Year <= 1995:\n",
    "\n",
    "        return '1990-1995' \n",
    "\n",
    "\n",
    "    elif  1996 <= x.Year <= 2000:\n",
    "\n",
    "        return '1996-2000' \n",
    "\n",
    "    elif  2001 <= x.Year <= 2005:\n",
    "\n",
    "        return '2001-2005' \n",
    "    \n",
    "    elif  2006 <= x.Year <= 2010:\n",
    "\n",
    "        return '2006-2010' \n",
    "\n",
    "    elif  2011 <= x.Year <= 2015:\n",
    "\n",
    "        return '2011-2015' \n",
    "    \n",
    "    elif  2016 <= x.Year <= 2020:\n",
    "\n",
    "        return '2016-2020' \n",
    "    \n",
    "    elif  2021 <= x.Year <= 2024:\n",
    "\n",
    "        return '2021-2024'     \n",
    "    \n",
    "\n",
    "\n",
    "# df_merge['Year_group'] = df_merge.apply(lambda x: year_group(x) ,1 )\n",
    "\n",
    "\n",
    "\n",
    "# Function to get time into seconds\n",
    "\n",
    "def time_format_to_sec_time(x):\n",
    "\n",
    "\n",
    "\n",
    "    if x.time_len == 2:\n",
    "\n",
    "\n",
    "       corrected_time =   int(x.Time.split(':')[0].strip())*60 +   int(x.Time.split(':')[1].strip()) \n",
    "    \n",
    "\n",
    "    elif x.time_len == 3:\n",
    "\n",
    "\n",
    "       corrected_time =   int(x.Time.split(':')[0].strip())*60*60 +   int(x.Time.split(':')[1].strip())*60 +   int(x.Time.split(':')[1].strip()) \n",
    "\n",
    "\n",
    "    return corrected_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to clean gender\n",
    "\n",
    "def gender_filter(x):\n",
    "\n",
    "\n",
    "    if x in ('M','MAS','MU','M4', 'M3','M5', 'M2', 'M7', 'MU'):\n",
    "\n",
    "        return 'M'\n",
    "    \n",
    "    elif x in ('F', 'F4', 'F5', 'F2', 'F3','F6'):\n",
    "\n",
    "        return 'F'\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return ''\n",
    "    \n",
    "\n",
    "# df_merge['Sex'] = df_merge['Sex'].apply(lambda x: gender_filter(x)  )\n",
    "\n",
    "\n",
    "# Functoin to clean Age Category\n",
    "\n",
    "def age_cat_filter(x):\n",
    "\n",
    "\n",
    "    if x in ('U19','U20','<20','-19'):\n",
    "\n",
    "        return 'U20'\n",
    "    \n",
    "    elif x in ('20-29','25-29','20-24'):\n",
    "\n",
    "        return '20-29'\n",
    "    \n",
    "    elif x in ('30-39','30-34','35-39'):\n",
    "\n",
    "        return '30-39'\n",
    "    \n",
    "    elif x in ('40-49','40-44','45-49'):\n",
    "\n",
    "        return '40-49'\n",
    "    \n",
    "    elif x in ('50-59','50-54','55-59'):\n",
    "\n",
    "        return '50-59'\n",
    "\n",
    "    elif x in ('60+','60-69','60-64','65-69'):\n",
    "\n",
    "        return '60-69'\n",
    "\n",
    "    elif x in ('70+','70-74','75-79'):\n",
    "\n",
    "        return '70-79'\n",
    "    \n",
    "    elif x in ('80+','85+','80-84'):\n",
    "\n",
    "        return '80+'\n",
    "\n",
    "# df_merge['Age_Cat_fix'] = df_merge.Age_Cat.apply(lambda x: age_cat_filter(x),1  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSqquare -  0.8617434324313943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reading the Data\n",
    "\n",
    "excel_file_path = r'C:\\Users\\Monk\\Codebase\\Tely 10\\Tely 10 All Data v2.xlsx'\n",
    "perc_90 = pd.read_excel(excel_file_path, sheet_name='10th Percentile')\n",
    "perc_50 = pd.read_excel(excel_file_path, sheet_name='50th Percentile')\n",
    "perc_10 = pd.read_excel(excel_file_path, sheet_name='90th Percentile')\n",
    "all_data = pd.read_excel(excel_file_path, sheet_name='All Data')\n",
    "\n",
    "\n",
    "# Plotting the data\n",
    "\n",
    "# perc_90.groupby('Year_group').agg({'Mets':'mean'}).plot(kind = 'line', figsize=(8,5))\n",
    "# perc_50.groupby('Year_group').agg({'Mets':'mean'}).plot(kind = 'line', figsize=(8,5))\n",
    "# perc_10.groupby('Year_group').agg({'Mets':'mean'}).plot(kind = 'line', figsize=(8,5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 10th Percentile\n",
    "\n",
    "\n",
    "model_10 = ols('Mets ~ C(Year) + Distance + Time_sec', data=perc_10).fit()\n",
    "aov_table_10 = sm.stats.anova_lm(model_10, typ=2)\n",
    "r2_10 = model_10.rsquared\n",
    "print('RSqquare - ',r2_10)\n",
    "\n",
    "\n",
    "# Tukey Table\n",
    "\n",
    "tukey_perc_10 = pairwise_tukeyhsd(endog=perc_10['Mets'], groups=perc_10['Year_group'],alpha=0.05)\n",
    "tukey_perc_10 = pd.DataFrame(tukey_perc_10.summary())\n",
    "\n",
    "\n",
    "# Tukey Table\n",
    "tukey_perc_10_columns = ['Group1','Group2','MeanDiff','p-adj','Lower','Upper','Rject']\n",
    "tukey_perc_10.columns = tukey_perc_10_columns\n",
    "tukey_perc_10 = tukey_perc_10[1:]\n",
    "\n",
    "# Average Mets Over the years\n",
    "perc_10_agg = perc_10.groupby('Year_group').agg({'Mets':'mean'}).reset_index()\n",
    "\n",
    "\n",
    "# 50th Percentile\n",
    "\n",
    "model_50 = ols('Mets ~ C(Year) + Distance + Time_sec ', data=perc_50).fit()\n",
    "aov_table_50 = sm.stats.anova_lm(model_50, typ=2)\n",
    "r2_50 = model_50.rsquared\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tukey_perc_50 = pairwise_tukeyhsd(endog=perc_50['Mets'], groups=perc_50['Year_group'],alpha=0.05)\n",
    "tukey_perc_50 = pd.DataFrame(tukey_perc_50.summary())\n",
    "\n",
    "\n",
    "# Tukey Table\n",
    "tukey_perc_50_columns = ['Group1','Group2','MeanDiff','p-adj','Lower','Upper','Rject']\n",
    "tukey_perc_50.columns = tukey_perc_50_columns\n",
    "tukey_perc_50 = tukey_perc_50[1:]\n",
    "\n",
    "# Average Mets Over the years\n",
    "perc_50_agg = perc_50.groupby('Year_group').agg({'Mets':'mean'}).reset_index()\n",
    "\n",
    "# 90th Percentile\n",
    "\n",
    "model_90 = ols('Mets ~ C(Year) + Distance + Time_sec ', data=perc_90).fit()\n",
    "aov_table_90 = sm.stats.anova_lm(model_90, typ=2)\n",
    "r2_90 = model_90.rsquared\n",
    "\n",
    "\n",
    "tukey_perc_90 = pairwise_tukeyhsd(endog=perc_90['Mets'], groups=perc_90['Year_group'],alpha=0.05)\n",
    "tukey_perc_90 = pd.DataFrame(tukey_perc_90.summary())\n",
    "\n",
    "# Tukey Table\n",
    "tukey_perc_90_columns = ['Group1','Group2','MeanDiff','p-adj','Lower','Upper','Rject']\n",
    "tukey_perc_90.columns = tukey_perc_90_columns\n",
    "tukey_perc_90 = tukey_perc_90[1:]\n",
    "\n",
    "# Average Mets Over the years\n",
    "perc_90_agg = perc_90.groupby('Year_group').agg({'Mets':'mean'}).reset_index()\n",
    "\n",
    "\n",
    "# Saving all the data into Excel file.\n",
    "\n",
    "writer = pd.ExcelWriter(r'C:\\Users\\Monk\\Codebase\\Tely 10\\Statistics Tely 10.xlsx')\n",
    "\n",
    "aov_table_10.to_excel(writer, sheet_name = 'ANOVA 10th')\n",
    "print('10',r2_10)\n",
    "tukey_perc_10.to_excel(writer, sheet_name = 'Tukey 10th')\n",
    "perc_10_agg.to_excel(writer, sheet_name = 'Avg Data 10th')\n",
    "\n",
    "\n",
    "aov_table_50.to_excel(writer, sheet_name = 'ANOVA 50th')\n",
    "print('50',r2_50)\n",
    "# r2_50.to_excel(writer, sheet_name = 'RSquare 50th')\n",
    "tukey_perc_50.to_excel(writer, sheet_name = 'Tukey 50th')\n",
    "perc_50_agg.to_excel(writer, sheet_name = 'Avg Data 50th')\n",
    "\n",
    "\n",
    "aov_table_90.to_excel(writer, sheet_name = 'ANOVA 90th')\n",
    "print('90',r2_90)\n",
    "# r2_90.to_excel(writer, sheet_name = 'RSquare 90th')\n",
    "tukey_perc_90.to_excel(writer, sheet_name = 'Tukey 90th')\n",
    "perc_90_agg.to_excel(writer, sheet_name = 'Avg Data 90th')\n",
    "\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codebase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
